{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "z7Bl-nArTO5d",
        "hoBbgedGnIK_",
        "hj4-KwPzWGx-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Check your Google Colab settings"
      ],
      "metadata": {
        "id": "xGx4M-Frw9ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uV_NGfQyAncI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44nCw9GqTKMC",
        "outputId": "f65f360c-f1fb-4d1c-f78e-6508b04f38b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15109 MiB, 15109 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/Change runtime type in the top bar.\n",
        "\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown (OPTIONAL) Mount your google drive folder and save files locally \n",
        "\n",
        "## this will require some changes in code to include different filepaths\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "spRpGaWpmKRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Sim Swap\n",
        "\n",
        "This part allows you to create a Deepfake given a source video and a target image.\n",
        "\n",
        "Code : https://github.com/neuralchen/SimSwap.  \n",
        "Paper: https://arxiv.org/pdf/2106.06340v1.pdf "
      ],
      "metadata": {
        "id": "z7Bl-nArTO5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation\n",
        "\n",
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ],
      "metadata": {
        "id": "yxUUh-s4TxrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "metadata": {
        "id": "EaNlGFhST062"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### If google drive link is not permenant, you can use ID from open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "metadata": {
        "id": "xSLSX8U6T6vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Now onedrive file can be downloaded in Colab directly!\n",
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/"
      ],
      "metadata": {
        "id": "BL-m0dKrULQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap import video_swap\n",
        "from util.add_watermark import watermark_image"
      ],
      "metadata": {
        "id": "8s9dOIQ9UVIt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "detransformer = transforms.Compose([\n",
        "        transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
        "        transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])\n",
        "    ])"
      ],
      "metadata": {
        "id": "GkjgCIzBUYY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Path of the source video.\n",
        "SOURCE_VIDEO = \"./demo_file/test.mp4\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path of the target image.\n",
        "TARGET_IMAGE = \"./demo_file/Iron_man.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Output file name. Will be saved in ./output folder .\n",
        "OUTPUT_FILE =  \"demo.mp4\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "E3XY_NutUeeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.pic_a_path = TARGET_IMAGE ## or replace it with image from your own google drive\n",
        "opt.video_path = SOURCE_VIDEO ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/' + OUTPUT_FILE\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = opt.crop_size\n",
        "\n",
        "torch.nn.Module.dump_patches = True\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pic_a = opt.pic_a_path\n",
        "    # img_a = Image.open(pic_a).convert('RGB')\n",
        "    img_a_whole = cv2.imread(pic_a)\n",
        "    img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "    img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
        "    img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "    img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "\n",
        "    # convert numpy to tensor\n",
        "    img_id = img_id.cuda()\n",
        "\n",
        "    #create latent id\n",
        "    img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
        "    latend_id = model.netArc(img_id_downsample)\n",
        "    latend_id = latend_id.detach().to('cpu')\n",
        "    latend_id = latend_id/np.linalg.norm(latend_id,axis=1,keepdims=True)\n",
        "    latend_id = latend_id.to('cuda')\n",
        "\n",
        "    video_swap(opt.video_path, latend_id, model, app, opt.output_path, temp_results_dir=opt.temp_path, use_mask=opt.use_mask)"
      ],
      "metadata": {
        "id": "tA297_d_UZDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display video\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "output_file = './output/' + OUTPUT_FILE\n",
        "mp4 = open(output_file,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "JlNMZlJ9V2dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download video\n",
        "from google.colab import files\n",
        "out_file = './output/' + OUTPUT_FILE\n",
        "files.download(out_file) "
      ],
      "metadata": {
        "id": "hiLGimQih7HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Real Time Voice Cloning\n",
        "\n",
        "This part allows you to clone a voice by providing a voice sample and an output text.\n",
        "\n",
        "Code: https://github.com/CorentinJ/Real-Time-Voice-Cloning\n",
        "\n",
        "Paper: https://arxiv.org/pdf/1806.04558.pdf"
      ],
      "metadata": {
        "id": "hoBbgedGnIK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation\n",
        "\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # go to root\n",
        "  %cd ../content/\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q --upgrade gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "  # download pretrained model\n",
        "  #!cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip\n",
        "  !cd {project_name} && mkdir -p output\n",
        "  !cd {project_name} && mkdir -p saved_models/default/ \n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1q8mEGwCkFy23KZsinbuvdKAQLqNKbYf1\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1EqFMIbvxffxtjiVrtykroF6_mUh-5Z3s\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1cf2NO6FtI0jDuy8AV3Xgn6leO6dHjIgu\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "!ls \n",
        "encoder.load_model(project_name / Path(\"saved_models/default/encoder.pt\"))\n",
        "synthesizer = Synthesizer(project_name / Path(\"saved_models/default/synthesizer.pt\"))\n",
        "vocoder.load_model(project_name / Path(\"saved_models/default/vocoder.pt\"))"
      ],
      "metadata": {
        "id": "GD-bsHFenntQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Record or Upload\n",
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) \n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "record_or_upload = \"Upload (.mp3 or .wav)\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "embedding = None\n",
        "def _compute_embedding(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  global embedding\n",
        "  embedding = None\n",
        "  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Your Voice\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  #button = widgets.Button(description=\"Upload Voice File\")\n",
        "  #button.on_click(_upload_audio)\n",
        "  _upload_audio(\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GvGG9kHPoooe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Synthesize text { run: \"auto\" }\n",
        "\n",
        "%cd /content/Real-Time-Voice-Cloning\n",
        "!pwd\n",
        "\n",
        "#Path of output audio file. Make sure that its .wav file\n",
        "OUTPUT_AUDIO = \"./output/generatedAudio.wav\" #@param {type:\"string\"}\n",
        "\n",
        "TEXT = \"Hey, this is me saying something completely different\" #@param {type:\"string\"}\n",
        "\n",
        "def synthesize(embed, text):\n",
        "  \n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  global generated_wav\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n",
        "  write(OUTPUT_AUDIO, synthesizer.sample_rate, generated_wav)\n",
        "if embedding is None:\n",
        "  print(\"first record a voice or upload a voice file!\")\n",
        "else:\n",
        "  synthesize(embedding, TEXT)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S3MPfl3CoyAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download audio\n",
        "from google.colab import files\n",
        "files.download(OUTPUT_AUDIO) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "i316yun5pLAk",
        "outputId": "d1a05ea1-8a42-44c2-adec-6d65ab8412d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd781b5c-93c7-4d76-829f-cc151b1cc1cd\", \"generated_Audio.wav\", 608058)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Wav2Lip\n",
        " \n",
        " This code lets you lipsync your videos based on the provided audio file.\n",
        " \n",
        " Code: https://github.com/Rudrabha/Wav2Lip\n",
        "\n",
        " Paper: https://arxiv.org/abs/2008.10010"
      ],
      "metadata": {
        "id": "hj4-KwPzWGx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation\n",
        "\n",
        "%cd ../content/\n",
        "!pwd\n",
        "!git clone https://github.com/zabique/Wav2Lip\n",
        "!cd Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O '/content/Wav2Lip/checkpoints/wav2lip.pth'\n",
        "!pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!pip install ffmpeg-python\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "print(\"\\nDone\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qm3olKRHj3pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "\n",
        "#@markdown Path of the audio source.\n",
        "SOURCE_AUDIO = \"/content/SimSwap/demo_file/voice.wav\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path of the video source\n",
        "TARGET_VIDEO = \"/content/SimSwap/output/demo.mp4\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path of the output video\n",
        "OUTPUT_VIDEO = \"/content/SimSwap/output/demoWav2Lip.mp4\" #@param {type:\"string\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "7eV8kUltXfSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Wav2Lip video\n",
        "\n",
        "# Using wav2lip_gan.pth GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face {TARGET_VIDEO} --audio {SOURCE_AUDIO} --outfile {OUTPUT_VIDEO}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2UyJbWOsXtls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display video\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open(OUTPUT_VIDEO,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "psQHGoc5lzLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download video\n",
        "\n",
        "from google.colab import files\n",
        "files.download(OUTPUT_VIDEO) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "q46VfPllX6iS",
        "outputId": "67b8c113-b8a3-4a69-b10a-22b25b5f48da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a72357ba-bbba-489a-9256-4a640fa745ce\", \"demoWav2Lip.mp4\", 529731)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}